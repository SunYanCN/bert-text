## 数据集介绍
- ChnSentiCorp 是中文情感分析数据集，其目标是判断一段话的情感态度，二分类任务。

## ChnSentiCorp运行结果
```bash
"""
Converting examples to features: 100%|████| 9600/9600 [00:07<00:00, 1236.69it/s]
Converting examples to features: 100%|████| 1200/1200 [00:00<00:00, 1366.45it/s]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_ids (InputLayer)          (None, 256)          0                                            
__________________________________________________________________________________________________
input_masks (InputLayer)        (None, 256)          0                                            
__________________________________________________________________________________________________
segment_ids (InputLayer)        (None, 256)          0                                            
__________________________________________________________________________________________________
bert_layer_1 (BertLayer)        (None, 768)          102880904   input_ids[0][0]                  
                                                                 input_masks[0][0]                
                                                                 segment_ids[0][0]                
__________________________________________________________________________________________________
dense (Dense)                   (None, 128)          98432       bert_layer_1[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            129         dense[0][0]                      
==================================================================================================
Total params: 102,979,465
Trainable params: 98,561
Non-trainable params: 102,880,904
__________________________________________________________________________________________________

Epoch 1/4  loss: 0.3052 - acc: 0.8754 - val_loss: 0.2681 - val_acc: 0.9058
Epoch 2/4  loss: 0.2318 - acc: 0.9099 - val_loss: 0.2462 - val_acc: 0.9167
Epoch 3/4  loss: 0.2089 - acc: 0.9195 - val_loss: 0.2325 - val_acc: 0.9225
Epoch 4/4  loss: 0.1951 - acc: 0.9220 - val_loss: 0.2336 - val_acc: 0.9192
"""
```
## 普通numpy和tf.data的输入方式性能
(tf.keras搭配tf.data多输入以及如何查看gpu利用率,花了我一天时间~)

左边是内存使用情况,右边是gpu利用率,最后算了平均值,感觉比较下来差别并不大。
### 普通numpy

![](https://user-gold-cdn.xitu.io/2019/6/13/16b50af51ae0dec1?w=640&h=480&f=png&s=29183)

mean mem_used:3.565377434914118,mean_gpu_0_proc:97.24629812438302

### tf.data

![](https://user-gold-cdn.xitu.io/2019/6/13/16b50e8727beef57?w=640&h=480&f=png&s=29202)

mean mem_used:3.6167192429642716,mean_gpu_0_proc:97.29809104258443
